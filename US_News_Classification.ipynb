{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import list\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from transformers import BertModel, DistilBertTokenizer, DistilBertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AlbertModel\n",
    "\n",
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please pick one among the available configs: ['sentences_allagree', 'sentences_75agree', 'sentences_66agree', 'sentences_50agree']\n",
    "#Example of usage:\n",
    "#load_dataset('financial_phrasebank', 'sentences_allagree')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (C:/Users/user/.cache/huggingface/datasets/financial_phrasebank/sentences_50agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653900a1ec184a1e8266a918301a93da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('financial_phrasebank', 'sentences_50agree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 =  부정 , 1 = 중립 , 2 = 긍정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataset['train']\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    text_label = [data_train['sentence'][i], data_train['label'][i]]\n",
    "    data_list.append(text_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4846"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전처리 부분 : 타 코트/논문 기반으로 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.594098\n",
       "2    0.281263\n",
       "0    0.124639\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.DataFrame(data_list)\n",
    "df_.columns = ['text','label']\n",
    "df_['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각각 데이터 떠로 두기 \n",
    "#data_list[0]\n",
    "text = []\n",
    "label = []\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    t = text_preprocessing(data_list[i][0])\n",
    "    t_split = t.split(' ')\n",
    "    t = text_word_one_limit(t_split)\n",
    "    l = data_list[i][1] \n",
    "    text.append(t)\n",
    "    label.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/검증/테스트 나누기  : 현재는 train 6 : val 2 : test 2  비율 - 데이터 수에 따라 조정 \n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(text, label, \n",
    "                                                                    random_state=42, \n",
    "                                                                    test_size=0.4, \n",
    "                                                                    stratify=label)\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=42, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본 훈련 진행 ㄱ  train / test  230313 \n",
    "\n",
    "# 훈련/검증/테스트 나누기  : 현재는 train 6 : val 2 : test 2  비율 - 데이터 수에 따라 조정 \n",
    "train_text, val_text, train_labels, val_labels = train_test_split(text, label, \n",
    "                                                                    random_state=42, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=label)\n",
    "\n",
    "test_text = val_text\n",
    "\n",
    "test_labels = val_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 많은 토큰 수 \n",
    "cnt = 0\n",
    "\n",
    "for i in range(len(text)):\n",
    "    txt = text[i]\n",
    "    txt = txt.split(' ')\n",
    "    if len(txt) > cnt:\n",
    "        cnt = len(txt) \n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기서 부터 모델링 부분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_path = 'google/electra-base-discriminator'  # \"monologg/koelectra-base-v3-discriminator\"\n",
    "model =   ElectraModel.from_pretrained(model_path)  # KoELECTRA-Small-v3\n",
    "tokenizer =  ElectraTokenizer.from_pretrained(model_path )\n",
    "\n",
    "#model_path = \"ProsusAI/finbert\" \n",
    "#model_path = 'yiyanghkust/finbert-pretrain'\n",
    "#model_path = 'microsoft/deberta-v3-base'\n",
    "#model_path = \"google/bigbird-roberta-base\"\n",
    "#model = AutoModel.from_pretrained(model_path)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "#model_path = 'xlnet-base-cased'\n",
    "#tokenizer = XLNetTokenizer.from_pretrained(model_path)\n",
    "#model = XLNetModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2342: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor 화\n",
    "\n",
    "# Specify `MAX_LEN`   , BERT의 최대는 512, 뉴스 문장의 수를 어느 정도할지 정하고 감소 정하기 \n",
    "MAX_LEN = 64\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "X_train = train_text\n",
    "X_val = val_text\n",
    "X_test = test_text\n",
    "y_train = train_labels\n",
    "y_val = val_labels\n",
    "y_test = test_labels\n",
    "\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
    "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size= batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size= batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Basic banking activities continued as normal',\n",
       " tensor([ 101, 3937, 8169, 3450, 2506, 2004, 3671,  102,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[65], train_inputs[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  0\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   1.006197   |     -      |     -     |   4.16   \n",
      "   1    |   40    |   0.927388   |     -      |     -     |   3.90   \n",
      "   1    |   60    |   0.824820   |     -      |     -     |   3.91   \n",
      "   1    |   80    |   0.834858   |     -      |     -     |   3.91   \n",
      "   1    |   100   |   0.689077   |     -      |     -     |   4.02   \n",
      "   1    |   120   |   0.705308   |     -      |     -     |   4.00   \n",
      "   1    |   140   |   0.634176   |     -      |     -     |   3.97   \n",
      "   1    |   160   |   0.613407   |     -      |     -     |   3.99   \n",
      "   1    |   180   |   0.603552   |     -      |     -     |   3.99   \n",
      "   1    |   200   |   0.491369   |     -      |     -     |   4.02   \n",
      "   1    |   220   |   0.480013   |     -      |     -     |   4.12   \n",
      "   1    |   240   |   0.481866   |     -      |     -     |   4.05   \n",
      "   1    |   242   |   0.673797   |     -      |     -     |   0.30   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.692158   |  0.481286  |   85.02   |   51.77  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.372435   |     -      |     -     |   4.14   \n",
      "   2    |   40    |   0.348091   |     -      |     -     |   4.03   \n",
      "   2    |   60    |   0.365558   |     -      |     -     |   4.02   \n",
      "   2    |   80    |   0.372466   |     -      |     -     |   3.95   \n",
      "   2    |   100   |   0.258229   |     -      |     -     |   3.99   \n",
      "   2    |   120   |   0.368836   |     -      |     -     |   3.93   \n",
      "   2    |   140   |   0.285646   |     -      |     -     |   3.97   \n",
      "   2    |   160   |   0.316067   |     -      |     -     |   3.97   \n",
      "   2    |   180   |   0.321778   |     -      |     -     |   3.96   \n",
      "   2    |   200   |   0.362977   |     -      |     -     |   4.00   \n",
      "   2    |   220   |   0.349197   |     -      |     -     |   3.96   \n",
      "   2    |   240   |   0.338248   |     -      |     -     |   3.95   \n",
      "   2    |   242   |   0.195554   |     -      |     -     |   0.29   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.337260   |  0.406620  |   84.82   |   51.61  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   20    |   0.157935   |     -      |     -     |   4.13   \n",
      "   3    |   40    |   0.202592   |     -      |     -     |   3.96   \n",
      "   3    |   60    |   0.246239   |     -      |     -     |   3.96   \n",
      "   3    |   80    |   0.220465   |     -      |     -     |   4.06   \n",
      "   3    |   100   |   0.230059   |     -      |     -     |   4.04   \n",
      "   3    |   120   |   0.196012   |     -      |     -     |   4.01   \n",
      "   3    |   140   |   0.205055   |     -      |     -     |   4.15   \n",
      "   3    |   160   |   0.221526   |     -      |     -     |   4.09   \n",
      "   3    |   180   |   0.179807   |     -      |     -     |   4.10   \n",
      "   3    |   200   |   0.287819   |     -      |     -     |   4.07   \n",
      "   3    |   220   |   0.262639   |     -      |     -     |   4.01   \n",
      "   3    |   240   |   0.203622   |     -      |     -     |   4.02   \n",
      "   3    |   242   |   0.247169   |     -      |     -     |   0.29   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.217809   |  0.440398  |   85.43   |   52.37  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   20    |   0.158433   |     -      |     -     |   4.18   \n",
      "   4    |   40    |   0.149472   |     -      |     -     |   4.05   \n",
      "   4    |   60    |   0.136755   |     -      |     -     |   4.04   \n",
      "   4    |   80    |   0.113775   |     -      |     -     |   4.01   \n",
      "   4    |   100   |   0.112477   |     -      |     -     |   3.96   \n",
      "   4    |   120   |   0.153513   |     -      |     -     |   3.97   \n",
      "   4    |   140   |   0.167287   |     -      |     -     |   4.01   \n",
      "   4    |   160   |   0.155282   |     -      |     -     |   4.01   \n",
      "   4    |   180   |   0.111438   |     -      |     -     |   3.99   \n",
      "   4    |   200   |   0.133997   |     -      |     -     |   4.09   \n",
      "   4    |   220   |   0.089999   |     -      |     -     |   4.03   \n",
      "   4    |   240   |   0.097376   |     -      |     -     |   4.05   \n",
      "   4    |   242   |   0.047044   |     -      |     -     |   0.32   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.131064   |  0.550023  |   85.74   |   52.22  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |   20    |   0.087226   |     -      |     -     |   4.19   \n",
      "   5    |   40    |   0.086083   |     -      |     -     |   4.12   \n",
      "   5    |   60    |   0.105959   |     -      |     -     |   4.03   \n",
      "   5    |   80    |   0.093704   |     -      |     -     |   3.99   \n",
      "   5    |   100   |   0.035962   |     -      |     -     |   3.99   \n",
      "   5    |   120   |   0.105982   |     -      |     -     |   3.96   \n",
      "   5    |   140   |   0.065467   |     -      |     -     |   3.98   \n",
      "   5    |   160   |   0.099227   |     -      |     -     |   4.06   \n",
      "   5    |   180   |   0.153176   |     -      |     -     |   4.04   \n",
      "   5    |   200   |   0.111687   |     -      |     -     |   3.99   \n",
      "   5    |   220   |   0.081368   |     -      |     -     |   3.95   \n",
      "   5    |   240   |   0.122443   |     -      |     -     |   3.99   \n",
      "   5    |   242   |   0.014981   |     -      |     -     |   0.29   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.094991   |  0.549535  |   86.45   |   52.05  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "## GPU 할당 및 loss 함수 및 모델 설정 및 학습 시작 \n",
    "\n",
    "# GPU 할당 변경하기\n",
    "GPU_NUM =  0# 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs= 5)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs= 5 , evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       121\n",
      "           1       0.91      0.86      0.89       576\n",
      "           2       0.81      0.84      0.82       273\n",
      "\n",
      "    accuracy                           0.86       970\n",
      "   macro avg       0.84      0.88      0.86       970\n",
      "weighted avg       0.87      0.86      0.87       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 임의 변수 옮김 & 모델 성능 평가 : val\n",
    "model = bert_classifier\n",
    "\n",
    "device = torch.device('cpu') # base 는 gpu인데... 여유 없을시 cpu\n",
    "\n",
    "    # Compute predicted probabilities on the test set\n",
    "probs = bert_predict(model, val_dataloader)  \n",
    "preds = probs\n",
    "test_y = val_labels\n",
    "\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 \n",
    "# 이미 디렉토리에 폴더가 있다면 이걸 쓰기 \n",
    "out_dir = './model' \n",
    "\n",
    "# 모델 폴더 만들기 : 있으면 x \n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    torch.save(model.state_dict(),  out_dir+ '/' + 'saved_weights_2303_acc86(50agree).pt')\n",
    "    #torch.save(model,  out_dir + '/' +  'pretrainded_model_230216' ) # 필요하다면 \n",
    "\n",
    "torch.save(model.state_dict(),  out_dir+ '/' + 'saved_weights_2303_acc86(50agree).pt') \n",
    "# saved_weights_220722_electra_un_base_v2_10\n",
    "#torch.save(model,  out_dir + '/' +  'pretrainded_model_220722_electra_un_base_v2_10' ) # 필요하다면 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/saved_weights_2303_acc86(50agree).pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장한 모델 가중치 불러오기 \n",
    "device = torch.device('cpu') \n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "model = BertClassifier()\n",
    "\n",
    "out_dir = './model' \n",
    "## saved_weights_220629.pt  5 epoch 모델 \n",
    "#load weights of best model\n",
    "path = out_dir+ '/' + 'saved_weights_2303_acc86(50agree).pt'\n",
    "print(path)\n",
    "model.load_state_dict(torch.load(path))  #, map_location=device   / strict = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       121\n",
      "           1       0.91      0.86      0.89       576\n",
      "           2       0.81      0.84      0.82       273\n",
      "\n",
      "    accuracy                           0.86       970\n",
      "   macro avg       0.84      0.88      0.86       970\n",
      "weighted avg       0.87      0.86      0.87       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검증 후 모델이 잘 학습되었다면 test set 기반 검증 : 만약, 문제가 있다면 모델 네트워크에서 수정 및 확인 \n",
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(model, test_dataloader)  \n",
    "preds = probs\n",
    "test_y = test_labels\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113,   7,   1],\n",
       "       [ 24, 498,  54],\n",
       "       [  3,  42, 228]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = preds\n",
    "y_true = test_y\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 230313    train / test 비율 맞추기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('For Telenor the three and half year contract is worth an estimated YIT has chosen Telenor and Elisa as its principal suppliers of ICT solutions in Norway Sweden Denmark and Finland',\n",
       " tensor(2))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 123\n",
    "test_text[n], test_labels[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Telenor the three and half year contract is worth an estimated YIT has chosen Telenor and Elisa as its principal suppliers of ICT solutions in Norway Sweden Denmark and Finland\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[5.2618352e-04, 5.4283824e-04, 9.9893099e-01]], dtype=float32), 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 220707 각각 개별 입력 분류 만들기  -> 개별 가능하게 수정하기 \n",
    "# torch.tensor 화\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "MAX_LEN = 64\n",
    "batch_size = 16\n",
    "\n",
    "X_pred =  test_text[n]\n",
    "#X_pred =  input()\n",
    "X_pred = text_preprocessing(X_pred)\n",
    "X_pred_split = X_pred.split(' ')\n",
    "X_pred = text_word_one_limit(X_pred_split)\n",
    "#print()\n",
    "print(X_pred)\n",
    "\n",
    "pred_inputs, pred_masks = preprocessing_for_bert([X_pred])\n",
    "#test_labels  torch.tensor(y_test)\n",
    "pred_dataset = TensorDataset(pred_inputs, pred_masks)\n",
    "pred_sampler = SequentialSampler(pred_dataset)\n",
    "pred_dataloader = DataLoader(pred_dataset, sampler=pred_sampler, batch_size= batch_size)\n",
    "\n",
    "#test_y = test_labels\n",
    "probs = bert_predict(model, pred_dataloader)  \n",
    "preds = np.argmax(probs, axis = 1)\n",
    "probs, preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Telenor the three and half year contract is worth an estimated YIT has chosen Telenor and Elisa as its principal suppliers of ICT solutions in Norway Sweden Denmark and Finland'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0][1]\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BigBirdModel(\n",
       "    (embeddings): BigBirdEmbeddings(\n",
       "      (word_embeddings): Embedding(50358, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BigBirdEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 21 14:55:44 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 166... WDDM  | 00000000:08:00.0  On |                  N/A |\n",
      "| 31%   36C    P8    14W / 125W |   5682MiB /  6144MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1132    C+G   ...indows\\System32\\mstsc.exe    N/A      |\n",
      "|    0   N/A  N/A      1260      C   ...ython\\Python37\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      1464    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      4220    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A      7960    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9536    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9968    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10060    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     13564    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13904    C+G   ...nger\\HiworksMessenger.exe    N/A      |\n",
      "|    0   N/A  N/A     14064    C+G   ...oft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     14600    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16196    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     17884    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     18360    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 함수들 \n",
    "def text_word_one_limit(t_split):\n",
    "\n",
    "    con_text = ''\n",
    "    for tn in range(len(t_split)):\n",
    "        tns = t_split[tn]\n",
    "        if len(tns) <= 1 :\n",
    "            continue\n",
    "\n",
    "        con_text = con_text + ' ' + tns  \n",
    "    return con_text.strip()\n",
    "\n",
    "# 전처리 함수, 추후 증권 뉴스에 맞게 일부 추가 및 수정 필요 \n",
    "def text_preprocessing(text):\n",
    "    cleaned_text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    #cleaned_text = re.sub('[a-zA-Z]', '', text) #숫자제외\n",
    "    cleaned_text = re.sub('\\n', '', cleaned_text)\n",
    "    cleaned_text = re.sub('\\xa0', '', cleaned_text) \n",
    "    cleaned_text = re.sub(\n",
    "        '[\\{\\}\\[\\]\\/?;:|\\)…－〕.〔ⓘㅇ÷♠♣＜＞©◀Ⅱ·―Ⅱ＆,？☏☎™×『』《》／┌─┬┐│├ ┼┤└┴┘★〈●○[］〉±▨→↑↓∼％「」※ㆍ♥①②③④⑤⑥⑦⑧⑨△◇ ㈜ⓝ◈；：“”‘’ *~【】♡♥▽▷ⓒ▣◇□㈜◆☞■▶▲▼`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]',\n",
    "        ' ', cleaned_text)\n",
    "    #cleaned_text = re.sub('    ', '', cleaned_text) \n",
    "    #cleaned_text = re.sub('   ', '', cleaned_text) \n",
    "    #cleaned_text = re.sub('  ', '', cleaned_text) \n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "## 헤드 테일 짜르기 \n",
    "def truncation_method(df, head, tail):  # 문서 리스트, head 자를 비율, tail 자를 비율 \n",
    "    target_dt = []\n",
    "    #head\n",
    "    head_n = int(510 * head) \n",
    "\n",
    "    #tail\n",
    "    tail_n = int(510 * tail) \n",
    "    \n",
    "    print(head_n, tail_n)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        target = df['text'][i]\n",
    "        #print(target)\n",
    "    \n",
    "        target_head = target[:head_n]  # head 짜르기 \n",
    "        \n",
    "        if len(target) > 510  : # 510 max_len\n",
    "            tail = len(target) - tail_n # 510\n",
    "            target_tail = target[tail:]\n",
    "            text = target_head + target_tail \n",
    "        else:\n",
    "            #tail = 0\n",
    "            text = target\n",
    "    \n",
    "        #print(len(target ), len(text), tail)\n",
    "        label = df['label'][i]\n",
    "        date = df['date'][i]\n",
    "        target_dt.append([label, text, date])\n",
    "\n",
    "    return target_dt\n",
    "\n",
    "def preprocessing_for_bert(data):\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sent,  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True,      # Return attention mask\n",
    "            truncation= True\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델 학습/검증/예측\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 256, 3\n",
    "        #D_in, H, D_out = 256, 256, 2\n",
    "        #D_in, H, D_out = 768, 50, 3\n",
    "        # Instantiate BERT model\n",
    "        #self.bert = DistilBertModel.from_pretrained(model_path)\n",
    "        self.bert = ElectraModel.from_pretrained(model_path) \n",
    "        #self.bert = AutoModel.from_pretrained(model_path) \n",
    "        #self.bert = XLNetModel.from_pretrained(model_path) \n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Dropout(0.25), \n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25), \n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr= 2e-5,    # Default learning rate  , Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler    \n",
    "\n",
    "    \n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    #model.eval()\n",
    "    model.eval().cpu()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "            \n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
